{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run.py [-h] [--random_seed RANDOM_SEED] [--is_training IS_TRAINING]\n",
      "              [--model_id MODEL_ID] [--model MODEL] [--data DATA]\n",
      "              [--root_path ROOT_PATH] [--data_path DATA_PATH]\n",
      "              [--features FEATURES] [--target TARGET] [--freq FREQ]\n",
      "              [--checkpoints CHECKPOINTS] [--embed EMBED] [--seq_len SEQ_LEN]\n",
      "              [--pred_len PRED_LEN] [--enc_in ENC_IN] [--patch_len PATCH_LEN]\n",
      "              [--stride STRIDE] [--padding_patch PADDING_PATCH]\n",
      "              [--d_model D_MODEL] [--dropout DROPOUT]\n",
      "              [--embed_type EMBED_TYPE] [--dec_in DEC_IN] [--c_out C_OUT]\n",
      "              [--n_heads N_HEADS] [--e_layers E_LAYERS] [--d_layers D_LAYERS]\n",
      "              [--d_ff D_FF] [--moving_avg MOVING_AVG] [--factor FACTOR]\n",
      "              [--distil] [--activation ACTIVATION]\n",
      "              [--res_attention RES_ATTENTION] [--label_len LABEL_LEN]\n",
      "              [--output_attention] [--do_predict] [--num_workers NUM_WORKERS]\n",
      "              [--itr ITR] [--train_epochs TRAIN_EPOCHS]\n",
      "              [--batch_size BATCH_SIZE] [--patience PATIENCE]\n",
      "              [--learning_rate LEARNING_RATE] [--des DES] [--loss LOSS]\n",
      "              [--lradj LRADJ] [--pct_start PCT_START] [--use_amp]\n",
      "              [--use_gpu USE_GPU] [--gpu GPU] [--use_multi_gpu]\n",
      "              [--devices DEVICES] [--test_flop]\n",
      "\n",
      "Autoformer & Transformer family for Time Series Forecasting\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --random_seed RANDOM_SEED\n",
      "                        random seed\n",
      "  --is_training IS_TRAINING\n",
      "                        status\n",
      "  --model_id MODEL_ID   model id\n",
      "  --model MODEL         model name, options: [Autoformer, Informer,\n",
      "                        Transformer]\n",
      "  --data DATA           dataset type\n",
      "  --root_path ROOT_PATH\n",
      "                        root path of the data file\n",
      "  --data_path DATA_PATH\n",
      "                        data file\n",
      "  --features FEATURES   forecasting task, options:[M, S, MS]; M:multivariate\n",
      "                        predict multivariate, S:univariate predict univariate,\n",
      "                        MS:multivariate predict univariate\n",
      "  --target TARGET       target feature in S or MS task\n",
      "  --freq FREQ           freq for time features encoding, options:[s:secondly,\n",
      "                        t:minutely, h:hourly, d:daily, b:business days,\n",
      "                        w:weekly, m:monthly], you can also use more detailed\n",
      "                        freq like 15min or 3h\n",
      "  --checkpoints CHECKPOINTS\n",
      "                        location of model checkpoints\n",
      "  --embed EMBED         time features encoding, options:[timeF, fixed,\n",
      "                        learned]\n",
      "  --seq_len SEQ_LEN     input sequence length\n",
      "  --pred_len PRED_LEN   prediction sequence length\n",
      "  --enc_in ENC_IN       channel or dimension\n",
      "  --patch_len PATCH_LEN\n",
      "                        patch length\n",
      "  --stride STRIDE       stride\n",
      "  --padding_patch PADDING_PATCH\n",
      "                        None: None; end: padding on the end\n",
      "  --d_model D_MODEL     dimension of model\n",
      "  --dropout DROPOUT     dropout\n",
      "  --embed_type EMBED_TYPE\n",
      "                        0: default 1: value embedding + temporal embedding +\n",
      "                        positional embedding 2: value embedding + temporal\n",
      "                        embedding 3: value embedding + positional embedding 4:\n",
      "                        value embedding\n",
      "  --dec_in DEC_IN       decoder input size\n",
      "  --c_out C_OUT         output size\n",
      "  --n_heads N_HEADS     num of heads\n",
      "  --e_layers E_LAYERS   num of encoder layers\n",
      "  --d_layers D_LAYERS   num of decoder layers\n",
      "  --d_ff D_FF           dimension of fcn\n",
      "  --moving_avg MOVING_AVG\n",
      "                        window size of moving average\n",
      "  --factor FACTOR       attn factor\n",
      "  --distil              whether to use distilling in encoder, using this\n",
      "                        argument means not using distilling\n",
      "  --activation ACTIVATION\n",
      "                        activation\n",
      "  --res_attention RES_ATTENTION\n",
      "                        res attention\n",
      "  --label_len LABEL_LEN\n",
      "                        unused fot this model\n",
      "  --output_attention    whether to output attention in ecoder\n",
      "  --do_predict          whether to predict unseen future data\n",
      "  --num_workers NUM_WORKERS\n",
      "                        data loader num workers\n",
      "  --itr ITR             experiments times\n",
      "  --train_epochs TRAIN_EPOCHS\n",
      "                        train epochs\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size of train input data\n",
      "  --patience PATIENCE   early stopping patience\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        optimizer learning rate\n",
      "  --des DES             exp description\n",
      "  --loss LOSS           loss function\n",
      "  --lradj LRADJ         adjust learning rate\n",
      "  --pct_start PCT_START\n",
      "                        pct_start\n",
      "  --use_amp             use automatic mixed precision training\n",
      "  --use_gpu USE_GPU     use gpu\n",
      "  --gpu GPU             gpu\n",
      "  --use_multi_gpu       use multiple gpus\n",
      "  --devices DEVICES     device ids of multile gpus\n",
      "  --test_flop           See utils/tools for usage\n"
     ]
    }
   ],
   "source": [
    "%run run.py \\\n",
    "     -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: --random_seed 42 --is_training 1 --root_path ./dataset/ --data_path ETTh1.csv --model_id ETTh1_96_96 --model TSMixer --data ETTh1 --features M --seq_len 720 --pred_len 96 --patch_len 48 --stride 48 --enc_in 7 --d_model 256 --dropout 0.2 --train_epochs 1 --patience 10 --itr 1 --batch_size 256 --learning_rate 0.001\n"
     ]
    }
   ],
   "source": [
    "%run run.py \\\n",
    "    --random_seed 42 \\\n",
    "    --is_training 1 \\\n",
    "    --root_path ./dataset/ \\\n",
    "    --data_path ETTh1.csv \\\n",
    "    --model_id ETTh1_96_96 \\\n",
    "    --model TSMixer \\\n",
    "    --data ETTh1 \\\n",
    "    --features M \\\n",
    "    --seq_len 720 \\\n",
    "    --pred_len 96 \\\n",
    "    --patch_len 48 \\\n",
    "    --stride 48 \\\n",
    "    --enc_in 7 \\\n",
    "    --d_model 256 \\\n",
    "    --dropout 0.2 \\\n",
    "    --train_epochs 1 \\\n",
    "    --patience 10 \\\n",
    "    --itr 1 --batch_size 256 --learning_rate 0.001\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
